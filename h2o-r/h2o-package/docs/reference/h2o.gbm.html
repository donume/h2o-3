<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Builds gradient boosted classification trees and gradient boosted regression trees on a parsed data set. — h2o.gbm • h2o</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>
  <link href="../extra.css" rel="stylesheet">
  <script src="../extra.js"></script>
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">h2o</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Using
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Getting Started</li>
    <li>
      <a href="../articles/basics.html">H2O Basics</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/h2oai/h2o-3">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Builds gradient boosted classification trees and gradient boosted regression trees on a parsed data set.</h1>
    </div>

    
    <p>The default distribution function will guess the model type based on the response column type.
In order to run properly, the response column must be an numeric for "gaussian" or an
enum for "bernoulli" or "multinomial".</p>
    

    <pre class="usage"><span class='fu'>h2o.gbm</span>(<span class='no'>x</span>, <span class='no'>y</span>, <span class='no'>training_frame</span>, <span class='kw'>model_id</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>validation_frame</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>nfolds</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>keep_cross_validation_predictions</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>keep_cross_validation_fold_assignment</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>score_each_iteration</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>score_tree_interval</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>fold_assignment</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"AUTO"</span>, <span class='st'>"Random"</span>, <span class='st'>"Modulo"</span>, <span class='st'>"Stratified"</span>),
  <span class='kw'>fold_column</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>ignore_const_cols</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>offset_column</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>weights_column</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>balance_classes</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>class_sampling_factors</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>max_after_balance_size</span> <span class='kw'>=</span> <span class='fl'>5</span>,
  <span class='kw'>max_hit_ratio_k</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>ntrees</span> <span class='kw'>=</span> <span class='fl'>50</span>, <span class='kw'>max_depth</span> <span class='kw'>=</span> <span class='fl'>5</span>, <span class='kw'>min_rows</span> <span class='kw'>=</span> <span class='fl'>10</span>,
  <span class='kw'>nbins</span> <span class='kw'>=</span> <span class='fl'>20</span>, <span class='kw'>nbins_top_level</span> <span class='kw'>=</span> <span class='fl'>1024</span>, <span class='kw'>nbins_cats</span> <span class='kw'>=</span> <span class='fl'>1024</span>,
  <span class='kw'>r2_stopping</span> <span class='kw'>=</span> <span class='fl'>Inf</span>, <span class='kw'>stopping_rounds</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>stopping_metric</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"AUTO"</span>,
  <span class='st'>"deviance"</span>, <span class='st'>"logloss"</span>, <span class='st'>"MSE"</span>, <span class='st'>"RMSE"</span>, <span class='st'>"MAE"</span>, <span class='st'>"RMSLE"</span>, <span class='st'>"AUC"</span>, <span class='st'>"lift_top_group"</span>,
  <span class='st'>"misclassification"</span>, <span class='st'>"mean_per_class_error"</span>), <span class='kw'>stopping_tolerance</span> <span class='kw'>=</span> <span class='fl'>0.001</span>,
  <span class='kw'>max_runtime_secs</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>seed</span> <span class='kw'>=</span> -<span class='fl'>1</span>, <span class='kw'>build_tree_one_node</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>learn_rate</span> <span class='kw'>=</span> <span class='fl'>0.1</span>, <span class='kw'>learn_rate_annealing</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>distribution</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"AUTO"</span>,
  <span class='st'>"bernoulli"</span>, <span class='st'>"multinomial"</span>, <span class='st'>"gaussian"</span>, <span class='st'>"poisson"</span>, <span class='st'>"gamma"</span>, <span class='st'>"tweedie"</span>,
  <span class='st'>"laplace"</span>, <span class='st'>"quantile"</span>, <span class='st'>"huber"</span>), <span class='kw'>quantile_alpha</span> <span class='kw'>=</span> <span class='fl'>0.5</span>,
  <span class='kw'>tweedie_power</span> <span class='kw'>=</span> <span class='fl'>1.5</span>, <span class='kw'>huber_alpha</span> <span class='kw'>=</span> <span class='fl'>0.9</span>, <span class='kw'>checkpoint</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>sample_rate</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>sample_rate_per_class</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>col_sample_rate</span> <span class='kw'>=</span> <span class='fl'>1</span>,
  <span class='kw'>col_sample_rate_change_per_level</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>col_sample_rate_per_tree</span> <span class='kw'>=</span> <span class='fl'>1</span>,
  <span class='kw'>min_split_improvement</span> <span class='kw'>=</span> <span class='fl'>1e-05</span>, <span class='kw'>histogram_type</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"AUTO"</span>,
  <span class='st'>"UniformAdaptive"</span>, <span class='st'>"Random"</span>, <span class='st'>"QuantilesGlobal"</span>, <span class='st'>"RoundRobin"</span>),
  <span class='kw'>max_abs_leafnode_pred</span> <span class='kw'>=</span> <span class='fl'>Inf</span>, <span class='kw'>pred_noise_bandwidth</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>categorical_encoding</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"AUTO"</span>, <span class='st'>"Enum"</span>, <span class='st'>"OneHotInternal"</span>, <span class='st'>"OneHotExplicit"</span>,
  <span class='st'>"Binary"</span>, <span class='st'>"Eigen"</span>, <span class='st'>"LabelEncoder"</span>, <span class='st'>"SortByResponse"</span>, <span class='st'>"EnumLimited"</span>),
  <span class='kw'>calibrate_model</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>calibration_frame</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>custom_metric_func</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>verbose</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p></td>
    </tr>
    <tr>
      <th>y</th>
      <td><p>The name or column index of the response variable in the data. The response must be either a numeric or a
categorical/factor variable. If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p></td>
    </tr>
    <tr>
      <th>training_frame</th>
      <td><p>Id of the training data frame.</p></td>
    </tr>
    <tr>
      <th>model_id</th>
      <td><p>Destination id for this model; auto-generated if not specified.</p></td>
    </tr>
    <tr>
      <th>validation_frame</th>
      <td><p>Id of the validation data frame.</p></td>
    </tr>
    <tr>
      <th>nfolds</th>
      <td><p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>keep_cross_validation_predictions</th>
      <td><p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>keep_cross_validation_fold_assignment</th>
      <td><p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>score_each_iteration</th>
      <td><p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>score_tree_interval</th>
      <td><p>Score the model after every so many trees. Disabled if set to 0. Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>fold_assignment</th>
      <td><p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: "AUTO",
"Random", "Modulo", "Stratified". Defaults to AUTO.</p></td>
    </tr>
    <tr>
      <th>fold_column</th>
      <td><p>Column with cross-validation fold index assignment per observation.</p></td>
    </tr>
    <tr>
      <th>ignore_const_cols</th>
      <td><p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p></td>
    </tr>
    <tr>
      <th>offset_column</th>
      <td><p>Offset column. This will be added to the combination of columns before applying the link function.</p></td>
    </tr>
    <tr>
      <th>weights_column</th>
      <td><p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor.</p></td>
    </tr>
    <tr>
      <th>balance_classes</th>
      <td><p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p></td>
    </tr>
    <tr>
      <th>class_sampling_factors</th>
      <td><p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p></td>
    </tr>
    <tr>
      <th>max_after_balance_size</th>
      <td><p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p></td>
    </tr>
    <tr>
      <th>max_hit_ratio_k</th>
      <td><p>Max. number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable)
Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>ntrees</th>
      <td><p>Number of trees. Defaults to 50.</p></td>
    </tr>
    <tr>
      <th>max_depth</th>
      <td><p>Maximum tree depth. Defaults to 5.</p></td>
    </tr>
    <tr>
      <th>min_rows</th>
      <td><p>Fewest allowed (weighted) observations in a leaf. Defaults to 10.</p></td>
    </tr>
    <tr>
      <th>nbins</th>
      <td><p>For numerical columns (real/int), build a histogram of (at least) this many bins, then split at the best point
Defaults to 20.</p></td>
    </tr>
    <tr>
      <th>nbins_top_level</th>
      <td><p>For numerical columns (real/int), build a histogram of (at most) this many bins at the root level, then
decrease by factor of two per level Defaults to 1024.</p></td>
    </tr>
    <tr>
      <th>nbins_cats</th>
      <td><p>For categorical columns (factors), build a histogram of this many bins, then split at the best point. Higher
values can lead to more overfitting. Defaults to 1024.</p></td>
    </tr>
    <tr>
      <th>r2_stopping</th>
      <td><p>r2_stopping is no longer supported and will be ignored if set - please use stopping_rounds, stopping_metric
and stopping_tolerance instead. Previous version of H2O would stop making trees when the R^2 metric equals or
exceeds this Defaults to 1.797693135e+308.</p></td>
    </tr>
    <tr>
      <th>stopping_rounds</th>
      <td><p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>stopping_metric</th>
      <td><p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression) Must be one of:
"AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE", "AUC", "lift_top_group", "misclassification",
"mean_per_class_error". Defaults to AUTO.</p></td>
    </tr>
    <tr>
      <th>stopping_tolerance</th>
      <td><p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.001.</p></td>
    </tr>
    <tr>
      <th>max_runtime_secs</th>
      <td><p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>seed</th>
      <td><p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default)
Defaults to -1 (time-based random number).</p></td>
    </tr>
    <tr>
      <th>build_tree_one_node</th>
      <td><p><code>Logical</code>. Run on one node only; no network overhead but fewer cpus used.  Suitable for small datasets.
Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>learn_rate</th>
      <td><p>Learning rate (from 0.0 to 1.0) Defaults to 0.1.</p></td>
    </tr>
    <tr>
      <th>learn_rate_annealing</th>
      <td><p>Scale the learning rate by this factor after each tree (e.g., 0.99 or 0.999)  Defaults to 1.</p></td>
    </tr>
    <tr>
      <th>distribution</th>
      <td><p>Distribution function Must be one of: "AUTO", "bernoulli", "multinomial", "gaussian", "poisson", "gamma",
"tweedie", "laplace", "quantile", "huber". Defaults to AUTO.</p></td>
    </tr>
    <tr>
      <th>quantile_alpha</th>
      <td><p>Desired quantile for Quantile regression, must be between 0 and 1. Defaults to 0.5.</p></td>
    </tr>
    <tr>
      <th>tweedie_power</th>
      <td><p>Tweedie power for Tweedie regression, must be between 1 and 2. Defaults to 1.5.</p></td>
    </tr>
    <tr>
      <th>huber_alpha</th>
      <td><p>Desired quantile for Huber/M-regression (threshold between quadratic and linear loss, must be between 0 and
1). Defaults to 0.9.</p></td>
    </tr>
    <tr>
      <th>checkpoint</th>
      <td><p>Model checkpoint to resume training with.</p></td>
    </tr>
    <tr>
      <th>sample_rate</th>
      <td><p>Row sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p></td>
    </tr>
    <tr>
      <th>sample_rate_per_class</th>
      <td><p>A list of row sample rates per class (relative fraction for each class, from 0.0 to 1.0), for each tree</p></td>
    </tr>
    <tr>
      <th>col_sample_rate</th>
      <td><p>Column sample rate (from 0.0 to 1.0) Defaults to 1.</p></td>
    </tr>
    <tr>
      <th>col_sample_rate_change_per_level</th>
      <td><p>Relative change of the column sampling rate for every level (from 0.0 to 2.0) Defaults to 1.</p></td>
    </tr>
    <tr>
      <th>col_sample_rate_per_tree</th>
      <td><p>Column sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p></td>
    </tr>
    <tr>
      <th>min_split_improvement</th>
      <td><p>Minimum relative improvement in squared error reduction for a split to happen Defaults to 1e-05.</p></td>
    </tr>
    <tr>
      <th>histogram_type</th>
      <td><p>What type of histogram to use for finding optimal split points Must be one of: "AUTO", "UniformAdaptive",
"Random", "QuantilesGlobal", "RoundRobin". Defaults to AUTO.</p></td>
    </tr>
    <tr>
      <th>max_abs_leafnode_pred</th>
      <td><p>Maximum absolute value of a leaf node prediction Defaults to 1.797693135e+308.</p></td>
    </tr>
    <tr>
      <th>pred_noise_bandwidth</th>
      <td><p>Bandwidth (sigma) of Gaussian multiplicative noise ~N(1,sigma) for tree node predictions Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>categorical_encoding</th>
      <td><p>Encoding scheme for categorical features Must be one of: "AUTO", "Enum", "OneHotInternal", "OneHotExplicit",
"Binary", "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited". Defaults to AUTO.</p></td>
    </tr>
    <tr>
      <th>calibrate_model</th>
      <td><p><code>Logical</code>. Use Platt Scaling to calculate calibrated class probabilities. Calibration can provide more
accurate estimates of class probabilities. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>calibration_frame</th>
      <td><p>Calibration frame for Platt Scaling</p></td>
    </tr>
    <tr>
      <th>custom_metric_func</th>
      <td><p>Reference to custom evaluation function, format: `language:keyName=funcName`</p></td>
    </tr>
    <tr>
      <th>verbose</th>
      <td><p><code>Logical</code>. Print scoring history to the console (Metrics per tree for GBM, DRF, &amp; XGBoost. Metrics per epoch for Deep Learning). Defaults to FALSE.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <p><code><a href='predict.H2OModel.html'>predict.H2OModel</a></code> for prediction</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='fu'>library</span>(<span class='no'>h2o</span>)
<span class='fu'><a href='h2o.init.html'>h2o.init</a></span>()</div><div class='output co'>#&gt; Reading in config file: ./../../../../.h2oconfig
#&gt;  Connection successful!
#&gt; 
#&gt; R is connected to the H2O cluster: 
#&gt;     H2O cluster uptime:         3 days 4 hours 
#&gt;     H2O cluster timezone:       
#&gt;     H2O data parsing timezone:  
#&gt;     H2O cluster version:        3.17.0.99999 
#&gt;     H2O cluster version age:    3 days  
#&gt;     H2O cluster name:           terrytangyuan 
#&gt;     H2O cluster total nodes:    1 
#&gt;     H2O cluster total memory:   15.82 GB 
#&gt;     H2O cluster total cores:    8 
#&gt;     H2O cluster allowed cores:  8 
#&gt;     H2O cluster healthy:        TRUE 
#&gt;     H2O Connection ip:          localhost 
#&gt;     H2O Connection port:        54321 
#&gt;     H2O Connection proxy:       NA 
#&gt;     H2O Internal Security:      FALSE 
#&gt;     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
#&gt;     R Version:                  R version 3.4.2 (2017-09-28) 
#&gt; </div><div class='input'>
<span class='co'># Run regression GBM on australia.hex data</span>
<span class='no'>ausPath</span> <span class='kw'>&lt;-</span> <span class='fu'>system.file</span>(<span class='st'>"extdata"</span>, <span class='st'>"australia.csv"</span>, <span class='kw'>package</span><span class='kw'>=</span><span class='st'>"h2o"</span>)
<span class='no'>australia.hex</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='h2o.importFile.html'>h2o.uploadFile</a></span>(<span class='kw'>path</span> <span class='kw'>=</span> <span class='no'>ausPath</span>)</div><div class='output co'>#&gt;   |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%</div><div class='input'><span class='no'>independent</span> <span class='kw'>&lt;-</span> <span class='fu'>c</span>(<span class='st'>"premax"</span>, <span class='st'>"salmax"</span>,<span class='st'>"minairtemp"</span>, <span class='st'>"maxairtemp"</span>, <span class='st'>"maxsst"</span>,
<span class='st'>"maxsoilmoist"</span>, <span class='st'>"Max_czcs"</span>)
<span class='no'>dependent</span> <span class='kw'>&lt;-</span> <span class='st'>"runoffnew"</span>
<span class='fu'>h2o.gbm</span>(<span class='kw'>y</span> <span class='kw'>=</span> <span class='no'>dependent</span>, <span class='kw'>x</span> <span class='kw'>=</span> <span class='no'>independent</span>, <span class='kw'>training_frame</span> <span class='kw'>=</span> <span class='no'>australia.hex</span>,
<span class='kw'>ntrees</span> <span class='kw'>=</span> <span class='fl'>3</span>, <span class='kw'>max_depth</span> <span class='kw'>=</span> <span class='fl'>3</span>, <span class='kw'>min_rows</span> <span class='kw'>=</span> <span class='fl'>2</span>)</div><div class='output co'>#&gt;   |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%</div><div class='output co'>#&gt; Model Details:
#&gt; ==============
#&gt; 
#&gt; H2ORegressionModel: gbm
#&gt; Model ID:  GBM_model_R_1512747612023_1052 
#&gt; Model Summary: 
#&gt;   number_of_trees number_of_internal_trees model_size_in_bytes min_depth
#&gt; 1               3                        3                 486         3
#&gt;   max_depth mean_depth min_leaves max_leaves mean_leaves
#&gt; 1         3    3.00000          8          8     8.00000
#&gt; 
#&gt; 
#&gt; H2ORegressionMetrics: gbm
#&gt; ** Reported on training data. **
#&gt; 
#&gt; MSE:  145451.3
#&gt; RMSE:  381.3808
#&gt; MAE:  255.4057
#&gt; RMSLE:  3.70591
#&gt; Mean Residual Deviance :  145451.3
#&gt; 
#&gt; 
#&gt; 
#&gt; </div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#see-also">See also</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by .</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
